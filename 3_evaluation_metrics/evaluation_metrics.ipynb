{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adbcfbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.1. evaluation metrics \n",
    "# (https://towardsdatascience.com/evaluation-metrics-for-machine-learning-2167fca1a291)\n",
    "\n",
    "# supervised evaluation metrics\n",
    "\n",
    "# common classification metrics:\n",
    "# accuracy\n",
    "# precision (P)\n",
    "# recall (R)\n",
    "# F1 score (F1)\n",
    "# area under the ROC (receiver operating characterisitc) curve or simpler AUC (AUC)\n",
    "# log loss\n",
    "# precision at k (P@k)\n",
    "# average precision at k (AP@k)\n",
    "# mean average precision at k (MAP@k)\n",
    "\n",
    "# common regression metrics:\n",
    "# mean absolute error (MAE)\n",
    "# mean squared error (MSE)\n",
    "# root mean squared error (RMSE)\n",
    "# root mean squared logarithmic error (RMSLE)\n",
    "# mean percentage error (MPE)\n",
    "# mean absolute percentage error (MAPE)\n",
    "# r^2 (R2 score)\n",
    "\n",
    "# knowing how these metrics work is important, but also knowing where to use them and on what kind of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "135d6512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we have a binary classification problem where there are an equal number of positive and negative samples\n",
    "# (e.g. over 100 sample 50 are positive and 50 negative)\n",
    "# we generally use accuracy, precision, recall and f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89803396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some data to test\n",
    "l1 = [0,1,1,1,0,0,0,1]\n",
    "l2 = [0,1,0,1,0,1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fed1f3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.625\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "# accuracy is one of the most straighforward metrics - if your model takes 100 images and correctly classifies 90 of them\n",
    "# the accuracy score is 90%\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate accuracy\n",
    "    :param y_ture: list of true vlaues\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: accuracy score\n",
    "    \"\"\"\n",
    "    # initialize a simple counter for correct predictions\n",
    "    correct_counter = 0\n",
    "    # loop over all elements of y_true\n",
    "    # and y_pred \"together\"\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == yp:\n",
    "           # if predicition is equal to truth, increase counter\n",
    "           correct_counter += 1\n",
    "            \n",
    "    # return accuracy\n",
    "    # which is correct predictions over the number of samples\n",
    "    return correct_counter / len(y_true)\n",
    "\n",
    "print('accuracy:' + str(accuracy(l1, l2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e733d672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.625\n"
     ]
    }
   ],
   "source": [
    "# also accuracy can be calculated using a built-in from scikit-learn\n",
    "from sklearn import metrics\n",
    "print('accuracy:' + str(metrics.accuracy_score(l1, l2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f810e745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the datset was changed slightly so that 90 samples were negative and 10 were positive, and cross validation had\n",
    "# been done in a manner so that the ratio was preserved \n",
    "# if you predicit all samples to be negative, the accuracy score would be 90% - without building a model\n",
    "# this is due to the large skew of the dataset\n",
    "# in these cases accuracy isn't the best metric to use (as you might get a high value for a bad model)\n",
    "\n",
    "# in these cases precision is a better metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "170a8884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of true positives: 2\n",
      "number of true negatives: 3\n",
      "number of false positives: 1\n",
      "number of false negatives: 2\n"
     ]
    }
   ],
   "source": [
    "# before looking at precision first we need to define some terms:\n",
    "\n",
    "# true positive (TP)\n",
    "# given a sample, if the model predicts it to be positive and the target is positive it is a true positive\n",
    "\n",
    "# true negative (TN)\n",
    "# given a sample, if the model predicts it to be negative and the target is negative it is a true negative\n",
    "\n",
    "# false positive (FP)\n",
    "# given a sample, if the model predicts it to be positive and the target is negative it is a false positive\n",
    "\n",
    "# false negative (FN)\n",
    "# given a sample, if the model predicts it to be negative and the target is positive it is a false negative\n",
    "\n",
    "# (assume in the dataset that 1 is positive and 0 is negative and it is a binary classification)\n",
    "\n",
    "def true_positive(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate true positives\n",
    "    :param y_ture: list of true vlaues\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: number of true positives\n",
    "    \"\"\"\n",
    "    # initialize\n",
    "    tp = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 1:\n",
    "            tp += 1\n",
    "    return tp\n",
    "\n",
    "def true_negative(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate true negatives\n",
    "    :param y_ture: list of true vlaues\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: number of true negatives\n",
    "    \"\"\"\n",
    "    # initialize\n",
    "    tn = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 0 and yp == 0:\n",
    "            tn += 1\n",
    "    return tn\n",
    "\n",
    "def false_positive(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate false positive\n",
    "    :param y_ture: list of true vlaues\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: number of false positives\n",
    "    \"\"\"\n",
    "    # initialize\n",
    "    fp = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 0 and yp == 1:\n",
    "            fp += 1\n",
    "    return fp\n",
    "\n",
    "def false_negative(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate false negative\n",
    "    :param y_ture: list of true vlaues\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: number of false negative\n",
    "    \"\"\"\n",
    "    # initialize\n",
    "    fn = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 0:\n",
    "            fn += 1\n",
    "    return fn\n",
    "\n",
    "print('number of true positives: ' + str(true_positive(l1, l2)))\n",
    "print('number of true negatives: ' + str(true_negative(l1, l2)))\n",
    "print('number of false positives: ' + str(false_positive(l1, l2)))\n",
    "print('number of false negatives: ' + str(false_negative(l1, l2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75299fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(V2): 0.625\n"
     ]
    }
   ],
   "source": [
    "# we can define accuracy using the terms above\n",
    "# accuracy score = (TP + TN)/(TP+TN+FP+FN)\n",
    "\n",
    "def accuracy_v2(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate accuracy using tp/tn/fp/fn\n",
    "    :param y_ture: list of true vlaues\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: accuracy score\n",
    "    \"\"\"  \n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    tn = true_negative(y_true, y_pred)\n",
    "    accuracy_score = (tp + tn) / (tp + tn + fp +fn)\n",
    "    return accuracy_score\n",
    "\n",
    "print('accuracy(V2): ' + str(accuracy_v2(l1, l2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad7b4f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# precision\n",
    "# precision = TP / (TP + FP)\n",
    "\n",
    "# if the model predicts:\n",
    "# TP: 8\n",
    "# TN: 80\n",
    "# FP: 10\n",
    "# FN: 2\n",
    "\n",
    "# then precision is 8/(8+10) = 0.444 so the model is correct 44.4% of the time when trying to identify a positive sample\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate precision\n",
    "    :param y_ture: list of true vlaues\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: precision score\n",
    "    \"\"\"\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    precision = tp / (tp + fp)\n",
    "    return precision\n",
    "\n",
    "print('precision: ' + str(precision(l1, l2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3db06ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.5\n"
     ]
    }
   ],
   "source": [
    "# recall\n",
    "# recall = TP / (TP + FN)\n",
    "\n",
    "# if the model predicts:\n",
    "# TP: 8\n",
    "# TN: 80\n",
    "# FP: 10\n",
    "# FN: 2\n",
    "\n",
    "# then recall is 8/(8+2) = 0.80 so the model correctly identifies 80% of positive samples\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate recall\n",
    "    :param y_ture: list of true vlaues\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: recall score\n",
    "    \"\"\"\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    recall = tp / (tp + fn)\n",
    "    return recall\n",
    "\n",
    "print('recall: ' + str(recall(l1, l2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2923fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# precision-recall curve\n",
    "# most models predict a probability, and we usually use a threshold value of 0.5\n",
    "# if this value is changed, the values of precision and recall can change drastically \n",
    "# if for every threshold value we choose we calculate precision and recall we can plot and define a curve\n",
    "# this is the precision-recall curve\n",
    "\n",
    "# create some data\n",
    "y_true = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
    "          1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
    "\n",
    "# these are the probability predictions (which most of the time are calculated at 0.5)\n",
    "y_pred=  [0.02638412, 0.11114267, 0.31620708,\n",
    "          0.04909370, 0.01914910, 0.17554844,\n",
    "          0.15952202, 0.03819563, 0.11639273,\n",
    "          0.07937700, 0.08584789, 0.39095342,\n",
    "          0.27259048, 0.03447096, 0.04644807,\n",
    "          0.03543574, 0.18521942, 0.05934905,\n",
    "          0.61977213, 0.33056815]\n",
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "# threshold values - don't worry yet how these are obtained\n",
    "thresholds = [0.04909370, 0.05934905, 0.07937700,\n",
    "              0.08584789, 0.11114267, 0.11639273,\n",
    "              0.15952202, 0.17554844, 0.18521942,\n",
    "              0.27259048, 0.31620708, 0.33056815,\n",
    "              0.39095342, 0.61977213]\n",
    "\n",
    "# for every threshold, calculate predictions in binary and append calculated precisions and recalls\n",
    "for i in thresholds:\n",
    "    temp_prediction = [1 if x >= i else 0 for x in y_pred]\n",
    "    p = precision(y_true, temp_prediction)\n",
    "    r = recall(y_true, temp_prediction)\n",
    "    precisions.append(p)\n",
    "    recalls.append(r)\n",
    "    \n",
    "# now plot these values\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(recalls, precisions)\n",
    "plt.xlabel('recall', fontsize=15)\n",
    "plt.ylabel('precision', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58b96206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the precision-recall curve looks very different from what is normally seen - this is due to a low sample number (20)\n",
    "# and only 3 of them were positive\n",
    "# it is difficult to choose a value for the threshold that give both a good precision and recall\n",
    "# if the threshold is too high then you have a smaller number of true positives and a higher number of false negatives\n",
    "# this will decrease the recall score however, the precision score will be high \n",
    "# if you reduce the threshold too low the false positive will increase a lot and precision will be less\n",
    "\n",
    "# both precision and recall range from 0 to 1 and a value to 1 is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2d2bff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.5714285714285715\n"
     ]
    }
   ],
   "source": [
    "# F1 score\n",
    "# the f1 metric combines both precision and recall - it is the weighted average (harmonic mean) of P and R\n",
    "# F1 = 2PR / (P + R)\n",
    "# or written as\n",
    "# F1 = 2TP / (2TP + FP + FN)\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate f1 score\n",
    "    :param y_ture: list of true vlaues\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: f1 score\n",
    "    \"\"\"\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    \n",
    "    score = 2 * p * r / (p + r)\n",
    "    \n",
    "    return score\n",
    "\n",
    "print('f1 score: ' + str(f1(l1, l2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4938e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:0.5714285714285715\n"
     ]
    }
   ],
   "source": [
    "# also the f1 socre can be calculated using a built-in from scikit-learn\n",
    "from sklearn import metrics\n",
    "print('accuracy:' + str(metrics.f1_score(l1, l2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "becefb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this means instead of just looking at precision and recall individually, the f1 score can be used\n",
    "# like prcision, recall and accuracy, the f1 score is ranges from 0 to 1 with 1 being perfect\n",
    "# when dealing with datasets that have a skew, we should look at f1 (or precision and recall) instead of accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3cb172f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpr: 0.5\n",
      "fpr: 0.25\n"
     ]
    }
   ],
   "source": [
    "# other metrics\n",
    "# true positive rate (TPR)\n",
    "# TPR = TP / (TP + FN)\n",
    "# this is the same as recall\n",
    "\n",
    "def tpr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate tpr\n",
    "    :param y_ture: list of true vlaues\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: tpr\n",
    "    \"\"\"\n",
    "    return recall(y_true, y_pred)\n",
    "\n",
    "# false positive rate (FPR)\n",
    "# FPR = FP / (TN + FP)\n",
    "\n",
    "def fpr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate fpr\n",
    "    :param y_ture: list of true vlaues\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: fpr\n",
    "    \"\"\"\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    tn = true_negative(y_true, y_pred)\n",
    "    return fp / (tn + fp)\n",
    "\n",
    "print('tpr: ' + str(tpr(l1, l2)))\n",
    "print('fpr: ' + str(fpr(l1, l2)))\n",
    "\n",
    "# also 1-FPR\n",
    "# known as specificity or true negative rate (TNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee490d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh:   [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.99, 1.0]\n",
      "tpr_list: [1.0, 1.0, 1.0, 0.8, 0.8, 0.8, 0.8, 0.6, 0.6, 0.4, 0.4, 0.2, 0.0]\n",
      "fpr_list: [1.0, 0.9, 0.7, 0.6, 0.3, 0.3, 0.2, 0.1, 0.1, 0.1, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# out of these terms, TPR and FPR are the most important \n",
    "# lets calculate these terms for different thresholds\n",
    "\n",
    "# empty lists to store tpr and fpr values\n",
    "tpr_list = []\n",
    "fpr_list = []\n",
    "\n",
    "# actual targets\n",
    "y_true = [0, 0, 0, 0, 1, 0, 1,\n",
    "          0, 0, 1, 0, 1, 0, 0, 1]\n",
    "\n",
    "# predicted probabilities of a sample being 1\n",
    "y_pred = [0.1, 0.3, 0.2, 0.6, 0.8, 0.05,\n",
    "          0.9, 0.5, 0.3, 0.66, 0.3, 0.2,\n",
    "          0.85, 0.15, 0.99]\n",
    "\n",
    "# handmade thresholds\n",
    "thresholds = [0, 0.1, 0.2, 0.3, 0.4, 0.5,\n",
    "              0.6, 0.7, 0.8, 0.85, 0.9, 0.99, 1.0]\n",
    "\n",
    "# loop over all thresholds\n",
    "for thresh in thresholds:\n",
    "    # calculate predictions for given threshold\n",
    "    temp_pred = [1 if x >= thresh else 0 for x in y_pred]\n",
    "    # calculate tpr \n",
    "    temp_tpr = tpr(y_true, temp_pred)\n",
    "    # calculate fpr\n",
    "    temp_fpr = fpr(y_true, temp_pred)\n",
    "    # append tpr and fpr to lists\n",
    "    tpr_list.append(temp_tpr)\n",
    "    fpr_list.append(temp_fpr)\n",
    "    \n",
    "print('thresh:   ' + str(thresholds))\n",
    "print('tpr_list: ' + str(tpr_list))\n",
    "print('fpr_list: ' + str(fpr_list))\n",
    "\n",
    "# we can then plot these lists with tpr on the y-axis and fpr on the x-axis\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.fill_between(fpr_list, tpr_list, alpha=0.4)\n",
    "plt.plot(fpr_list, tpr_list, lw=3)\n",
    "plt.xlim(0, 1.0)\n",
    "plt.ylim(0, 1.0)\n",
    "plt.xlabel('FPR', fontsize=15)\n",
    "plt.xlabel('TPR', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ff3171d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8300000000000001\n"
     ]
    }
   ],
   "source": [
    "# this curve is known as the receiver operating characterisitc (ROC)\n",
    "# if we calculate the area under the ROC we get another metric, known as the area under the ROC curve\n",
    "# or area under curve (AUC)\n",
    "# there is a built in from sci-kit learn that allows this to be calculated\n",
    "\n",
    "from sklearn import metrics\n",
    "print('AUC: ' + str(metrics.roc_auc_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f468546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thresh:  [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.99, 1.0]\n",
      "tp_list: [5, 5, 5, 4, 4, 4, 4, 3, 3, 2, 2, 1, 0]\n",
      "fp_list: [10, 9, 7, 6, 3, 3, 2, 1, 1, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# AUC values range from 0 to 1\n",
    "\n",
    "# a value of 1 implies a perfect model (however this in practice normally means a mistake in cross validation)\n",
    "# a value of 0 implies your model is very bad (or very good). Here try inverting the probabilities for the predictions\n",
    "# if the probability for the positive class is p, try 1-p. This kind of AUC may also mean there is a problem with cross\n",
    "# validation or data processing\n",
    "# a value of 0.5 implies that the predictions are random. if you predict all targets as 0.5, the AUC will be 0.5\n",
    "# therefore a value between 0 and 0.5 implies the model is worse than random (this is likely due to the classes being \n",
    "# inverted and therefore try to run again with after inverting some classes)\n",
    "# say a model gives a score of 0.85, this means when a positive and negative sample are selected then the positive sample\n",
    "# will rank higher than the negative sample with a probability of 0.85\n",
    "\n",
    "# after obtaining the AUC you then make predictions on the test set\n",
    "# depending on the problem you will either want the probabilites or the acutal classes\n",
    "# the probabilities are already there, but to get the classes you need to select a threshold\n",
    "# for binary classifiction you can noramlly do something like:\n",
    "# prediction = probability >= threshold\n",
    "# this means that prediction is a new list that only contains binary variables (an item is 1 if the probability is greater\n",
    "# than or equal to the threshold and 0 for below)\n",
    "\n",
    "# you can use the ROC curve to choose the threshold, as it shows the tpr and fpr, and in turn tp and fp for different \n",
    "# thresholds. then choose the threshold depending what you want to optimise for your problem\n",
    "# therefore if you don't want many fp, choose a high threshold, but this will give more fn - it is a trade-off\n",
    "\n",
    "# we can see how thresholds effect tp and fp values\n",
    "\n",
    "# empty lists to store true positive and false positive values\n",
    "tp_list = []\n",
    "fp_list = []\n",
    "\n",
    "# loop over all thresholds\n",
    "for thresh in thresholds:\n",
    "    # calculate predictions for a given threshold\n",
    "    temp_pred = [1 if x >= thresh else 0 for x in y_pred]\n",
    "    # calculate tp\n",
    "    temp_tp = true_positive(y_true, temp_pred)\n",
    "    # calculate fp\n",
    "    temp_fp = false_positive(y_true, temp_pred)\n",
    "    # append tp and fp to lists\n",
    "    tp_list.append(temp_tp)\n",
    "    fp_list.append(temp_fp)\n",
    "    \n",
    "print('thresh:  ' + str(thresholds))\n",
    "print('tp_list: ' + str(tp_list))\n",
    "print('fp_list: ' + str(fp_list))\n",
    "\n",
    "# usually looking at the top left value on the ROC give a good threshold, this is 0.6\n",
    "# looking at the tp and fp values this means we don't loose too many tp and neither are there too many fp\n",
    "\n",
    "# the AUC is widely used for skewed binary classification problems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d73fbc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss: 0.49882711861432294\n",
      "log_loss form sklearn: 0.49882711861432294\n"
     ]
    }
   ],
   "source": [
    "# another important metric is the log loss metric\n",
    "# for a binary clasification it is defined as:\n",
    "# log loss = - 1.0 * (target*log(prediction) + (1 - target)*log(1 - prediction))\n",
    "# where target is either 0 or 1 and prediction is a probability of a sample belonging to class 1\n",
    "# for multiple samples in a dataset, the log loss over all samples is the average for all individual log losses\n",
    "# the log loss penalizes quite high for an incorrect or far-off prediction - it penalizes for being very sure and \n",
    "# very wrong\n",
    "import numpy as np\n",
    "\n",
    "def log_loss(y_true, y_proba):\n",
    "    \"\"\"\n",
    "    Function to calculate log loss\n",
    "    :param y_ture: list of true vlaues\n",
    "    :param y_proba: list of probabilities for 1\n",
    "    :return: overall log loss\n",
    "    \"\"\"\n",
    "    # define an epsilon values - this can also be input\n",
    "    # this values is used to clip probabilities\n",
    "    epsilon = 1e-15\n",
    "    # initialize empty list to store individual losses \n",
    "    loss = []\n",
    "    # loop over all true and predicted probability values\n",
    "    for yt, yp in zip(y_true, y_proba):\n",
    "        # adjust the probability \n",
    "        # 0 gets converted to 1e-15\n",
    "        # 1 gets converted to 1-1e-15\n",
    "        yp = np.clip(yp, epsilon, 1 - epsilon)\n",
    "        # calculate loss for one sample\n",
    "        temp_loss = - 1.0 * (\n",
    "            yt * np.log(yp)\n",
    "            + (1 - yt) * np.log(1 - yp)\n",
    "        )\n",
    "        # add to loss list\n",
    "        loss.append(temp_loss)\n",
    "    # return mean loss over all samples\n",
    "    return np.mean(loss)\n",
    "\n",
    "# test log loss function\n",
    "y_true = [0, 0, 0, 0, 1, 0, 1, \n",
    "          0, 0, 1, 0, 1, 0, 0, 1]\n",
    "y_proba = [0.1, 0.3, 0.2, 0.6, 0.8, 0.05,\n",
    "           0.9, 0.5, 0.3, 0.66, 0.3, 0.2,\n",
    "           0.85, 0.15, 0.99]\n",
    "\n",
    "print('log_loss: ' + str(log_loss(y_true, y_proba)))\n",
    "\n",
    "# check with sklearn built in\n",
    "from sklearn import metrics\n",
    "print('log_loss form sklearn: ' + str(metrics.log_loss(y_true, y_proba)))\n",
    "      \n",
    "# log loss penalizes a lot more than other metrics\n",
    "# if you were 51% sure about a sample belonging to class 1, the log loss would be:\n",
    "# -1.0*(1*log(0.51)+(1-1)*log(1-0.51)) = 0.67\n",
    "# and for 49% sure that a sample belonged to class 0:\n",
    "# -1.0*(0*log(0.49)+(1-0)*log(1-0.49)) = 0.67\n",
    "# therefore even if 0.5 gives perfect predictions, you will still have a high loss\n",
    "# any non-confident prediction will have a very high log loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "904f031a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro\n",
      "own:0.3611111111111111\n",
      "sklearn: 0.3611111111111111\n",
      "micro\n",
      "own:0.4444444444444444\n",
      "sklearn: 0.4444444444444444\n",
      "weighted\n",
      "own:0.39814814814814814\n",
      "sklearn: 0.39814814814814814\n"
     ]
    }
   ],
   "source": [
    "# most of the metrics discussed up to this point can be converted for multi-class classification problems\n",
    "# lets take precision and recall and convert to a multi-class version\n",
    "\n",
    "# there are three different ways to calculate this (lets look at percision):\n",
    "# macro averaged precision - calculate precision from all classes individually and then average\n",
    "# micro averaged precision - calculate class wide true positive and false positive, then use this to calculate precision\n",
    "# overall\n",
    "# weighted precision - same as macro but in this case it is the weighted average depending on the number of items in each\n",
    "# classs\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def macro_precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate macro averaged precision\n",
    "    :param y_true: list of true vlaues\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: macro averaged precision score\n",
    "    \"\"\"\n",
    "    # find the number of classes by taking the length of unique values in true list\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    # initialize precision to 0\n",
    "    precision = 0\n",
    "    # loop over all classes\n",
    "    for class_ in range(num_classes):\n",
    "        # all classes execpt current are considered negative\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        # calculate true positive for current class\n",
    "        tp = true_positive(temp_true, temp_pred)\n",
    "        # calculate false positive for current class\n",
    "        fp = false_positive(temp_true, temp_pred)\n",
    "        # calculate precision for current class\n",
    "        temp_precision = tp / (tp +fp)\n",
    "        # keep adding precision for all classes\n",
    "        precision += temp_precision\n",
    "    # calculate and return average precision over all classes\n",
    "    precision /= num_classes\n",
    "    return precision\n",
    "\n",
    "def micro_precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate micro averaged precision\n",
    "    :param y_true: list of true vlaues\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: micro averaged precision score\n",
    "    \"\"\"\n",
    "    # find the number of classes by taking the length of unique values in true list\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    # initialize tp and fp to 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    # loop over all classes\n",
    "    for class_ in range(num_classes):\n",
    "        # all classes except current are considered negative\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        # calculate true positive for current class and update overall tp\n",
    "        tp += true_positive(temp_true, temp_pred)\n",
    "        # calculate false positive for current class and update overall fp\n",
    "        fp += false_positive(temp_true, temp_pred)\n",
    "    # calculate and return overall precision\n",
    "    precision = tp / (tp + fp)\n",
    "    return precision\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def weighted_precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate weighted averaged precision\n",
    "    :param y_true: list of true vlaues\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: weighted averaged precision score\n",
    "    \"\"\"\n",
    "    # find the number of classes by taking the length of unique values in true list\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    # create class:sample count dictionary \n",
    "    # e.g. {0:25, 1:15, 2:21}\\\n",
    "    class_counts = Counter(y_true)\n",
    "    # initialize precision to 0\n",
    "    precision = 0\n",
    "    # loop over all classes \n",
    "    for class_ in range(num_classes):\n",
    "        # all classes except current are considered negative\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        # calculate tp and fp for class\n",
    "        tp = true_positive(temp_true, temp_pred)\n",
    "        fp = false_positive(temp_true, temp_pred)\n",
    "        # calculate precision of class\n",
    "        temp_precision = tp / (tp + fp)\n",
    "        # multiply precision with count of samples in class\n",
    "        weighted_precision = class_counts[class_] * temp_precision\n",
    "        # add to overall precision\n",
    "        precision += weighted_precision\n",
    "    # calculate overall precision by dividing by total number of samples\n",
    "    overall_precision = precision / len(y_true)\n",
    "    return overall_precision\n",
    "\n",
    "# test functions against sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "y_true = [0, 1, 2, 0, 1, 2, 0, 2, 2]\n",
    "y_pred = [0, 2 ,1, 0, 2, 1, 0, 0, 2]\n",
    "\n",
    "print('macro')\n",
    "print('own:' + str(macro_precision(y_true, y_pred)))\n",
    "print('sklearn: ' + str(metrics.precision_score(y_true, y_pred, average=\"macro\")))\n",
    "\n",
    "print('micro')\n",
    "print('own:' + str(micro_precision(y_true, y_pred)))\n",
    "print('sklearn: ' + str(metrics.precision_score(y_true, y_pred, average=\"micro\")))\n",
    "\n",
    "print('weighted')\n",
    "print('own:' + str(weighted_precision(y_true, y_pred)))\n",
    "print('sklearn: ' + str(metrics.precision_score(y_true, y_pred, average=\"weighted\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72e195fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted f1\n",
      "own: 0.2857142857142857\n",
      "sklearn: 0.41269841269841273\n"
     ]
    }
   ],
   "source": [
    "# the recall metric can also be implemented for multi-class in a simular way \n",
    "# both precision and recall depend on true positive, false positive and false negative\n",
    "# f1 depends on precision and recall\n",
    "\n",
    "# these are implemented in a simular way to the above precision\n",
    "# as an example the f1 multi-class weighted average is shown here:\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def weighted_f1(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate weighted f1 score\n",
    "    :param y_true: list of true vlaues\n",
    "    :param y_pred: list of predicted values\n",
    "    :return: weighted f1 score\n",
    "    \"\"\"\n",
    "    # find the number of classes by taking length of unique values in true list\n",
    "    num_classes = len(np.unique(y_true))\n",
    "    # create class:sample count dictionary\n",
    "    # e.g. {0:20, 1:15, 2:21}\n",
    "    class_counts = Counter(y_true)\n",
    "    # initialize f1 to 0\n",
    "    f1 = 0\n",
    "    # loop over all classes\n",
    "    for class_ in range(num_classes):\n",
    "        # all classes except current are considered negative\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        # calculate precision and recall for class\n",
    "        p = precision(temp_true, temp_pred)\n",
    "        r = recall(temp_true, temp_pred)\n",
    "        # calculate f1 of class\n",
    "        if p + r != 0:\n",
    "            temp_f1 = 2 * p * r / (p + r)\n",
    "        else:\n",
    "            temp_f1 = 0\n",
    "        # multiply f1 with count of samples in class\n",
    "        weighted_f1 = class_counts[class_] * temp_f1\n",
    "        # add to f1 precision\n",
    "        f1 += weighted_f1\n",
    "        # calculate overall f1 by dividing by total number of samples\n",
    "        overall_f1 = f1 / len(y_true)\n",
    "        return overall_f1\n",
    "    \n",
    "# test functions against sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "y_true = [0, 1, 2, 0, 1, 2, 0, 2, 2]\n",
    "y_pred = [0, 2 ,1, 0, 2, 1, 0, 0, 2]\n",
    "\n",
    "print('weighted f1')\n",
    "print('own: ' + str(weighted_f1(y_true, y_pred)))\n",
    "print('sklearn: ' + str(metrics.f1_score(y_true, y_pred, average=\"weighted\")))\n",
    "\n",
    "### THIS DOES NOT MATCH -- CHECK CODE!!! ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa6518fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 48.5, 'Predicted Labels')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AUC and log loss can be converted to multi-class formats too (this conversion is known as on-vs-all)\n",
    "# for binary and multi-class classification it is also popular to look at the confusion matrix\n",
    "# this is a table of TP, FP, TN, and FN\n",
    "# it can be used to see how many samples were miscalssified ans how many were correctly classified\n",
    "# to build the confusion matrix we just need TP, FP, TN, FN - this is also true of precision, recall, f1\n",
    "# and AUC\n",
    "# FP can sometimes be called a type-I error and FN as type-II error\n",
    "\n",
    "# the confusion matrix can also be expanded from binary to multi-class\n",
    "# if there are N classes, the matrix has shape NxN\n",
    "# if we have the following acutal classes:\n",
    "#        [0, 1, 2, 0, 1, 2, 0, 2, 2]\n",
    "# and the predictions are:\n",
    "#        [0, 2, 1, 0, 2, 1, 0, 0, 2]\n",
    "# the matrix would look like:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "# targets\n",
    "y_true = [0, 1, 2, 0, 1, 2, 0, 2, 2]\n",
    "# predictions\n",
    "y_pred = [0, 2, 1, 0, 2, 1, 0, 0, 2]\n",
    "\n",
    "# get confusion matrix from sklearn\n",
    "cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "# plot figure\n",
    "plt.figure(figsize=(10, 10))\n",
    "cmap = sns.cubehelix_palette(50, hue=0.05, rot=0, light=0.9, dark=0, as_cmap=True)\n",
    "sns.set(font_scale=2.5)\n",
    "sns.heatmap(cm, annot=True, cmap=cmap, cbar=False)\n",
    "plt.ylabel('Actucal Labels', fontsize=20)\n",
    "plt.xlabel('Predicted Labels', fontsize=20)\n",
    "\n",
    "\n",
    "# looking at class 0, there are three in the targets (acutal), and four in the predicted\n",
    "# three were in in the correct place, and plot 0, 0. the other was in the place of class 2 and plot 0, 2\n",
    "# a perfect matrix should just be filled along the diagonal with zeros elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e3973de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        y_true=[1, 2, 3]\n",
      "        y_pred=[0, 1, 2]\n",
      "        AP@1=0.0\n",
      "        \n",
      "\n",
      "        y_true=[1, 2, 3]\n",
      "        y_pred=[0, 1, 2]\n",
      "        AP@2=0.25\n",
      "        \n",
      "\n",
      "        y_true=[1, 2, 3]\n",
      "        y_pred=[0, 1, 2]\n",
      "        AP@3=0.38888888888888884\n",
      "        \n",
      "\n",
      "        y_true=[0, 2]\n",
      "        y_pred=[1]\n",
      "        AP@1=0.0\n",
      "        \n",
      "\n",
      "        y_true=[0, 2]\n",
      "        y_pred=[1]\n",
      "        AP@2=0.0\n",
      "        \n",
      "\n",
      "        y_true=[0, 2]\n",
      "        y_pred=[1]\n",
      "        AP@3=0.0\n",
      "        \n",
      "\n",
      "        y_true=[1]\n",
      "        y_pred=[0, 2, 3]\n",
      "        AP@1=0.0\n",
      "        \n",
      "\n",
      "        y_true=[1]\n",
      "        y_pred=[0, 2, 3]\n",
      "        AP@2=0.0\n",
      "        \n",
      "\n",
      "        y_true=[1]\n",
      "        y_pred=[0, 2, 3]\n",
      "        AP@3=0.0\n",
      "        \n",
      "\n",
      "        y_true=[2, 3]\n",
      "        y_pred=[2, 3, 4, 0]\n",
      "        AP@1=1.0\n",
      "        \n",
      "\n",
      "        y_true=[2, 3]\n",
      "        y_pred=[2, 3, 4, 0]\n",
      "        AP@2=1.0\n",
      "        \n",
      "\n",
      "        y_true=[2, 3]\n",
      "        y_pred=[2, 3, 4, 0]\n",
      "        AP@3=0.8888888888888888\n",
      "        \n",
      "\n",
      "        y_true=[1, 0]\n",
      "        y_pred=[0, 1, 2]\n",
      "        AP@1=1.0\n",
      "        \n",
      "\n",
      "        y_true=[1, 0]\n",
      "        y_pred=[0, 1, 2]\n",
      "        AP@2=1.0\n",
      "        \n",
      "\n",
      "        y_true=[1, 0]\n",
      "        y_pred=[0, 1, 2]\n",
      "        AP@3=0.8888888888888888\n",
      "        \n",
      "\n",
      "        y_true=[]\n",
      "        y_pred=[0]\n",
      "        AP@1=0.0\n",
      "        \n",
      "\n",
      "        y_true=[]\n",
      "        y_pred=[0]\n",
      "        AP@2=0.0\n",
      "        \n",
      "\n",
      "        y_true=[]\n",
      "        y_pred=[0]\n",
      "        AP@3=0.0\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# so far we have metrics for binary and multi-class, now we need metrics for the other type of classification problem\n",
    "# multi-label classification:\n",
    "# this is where each sample has one or more label associated with it (e.g. different objects within a given image)\n",
    "\n",
    "# the metrics for these problems are:\n",
    "# precision at k (P@k)\n",
    "# average precision at k (AP@k)\n",
    "# mean average precision at k (MAP@k)\n",
    "# log loss\n",
    "\n",
    "# P@k:\n",
    "# https://towardsdatascience.com/breaking-down-mean-average-precision-map-ae462f623a52\n",
    "# \n",
    "\n",
    "def pk(y_true, y_pred, k):\n",
    "    \"\"\"\n",
    "    Function to calculate precision at k\n",
    "    :param y_true: list of values, actual classes\n",
    "    :param y_pred: list of values, predicted classes\n",
    "    :return: precision at a given k\n",
    "    \"\"\"\n",
    "    # if k is 0 return 0 - this should never happen as k is always >= 1\n",
    "    if k == 0:\n",
    "        return 0\n",
    "    # interested in only top k predictions\n",
    "    y_pred = y_pred[:k]\n",
    "    # convert predictions to set\n",
    "    pred_set = set(y_pred)\n",
    "    # convert actual to set\n",
    "    true_set = set(y_true)\n",
    "    # find common values\n",
    "    common_values = pred_set.intersection(true_set)\n",
    "    # return length of common values over k\n",
    "    return len(common_values) / len(y_pred[:k])\n",
    "\n",
    "# we also have AP@k (P@1 to P@k and averaged)\n",
    "def apk(y_true, y_pred, k):\n",
    "    \"\"\"\n",
    "    Function to calculate average precision at k for single sample\n",
    "    :param y_true: list of values, actual classes\n",
    "    :param y_pred: list of values, predicted classes\n",
    "    :return: average precision at a given k\n",
    "    \"\"\"\n",
    "    # initialize p@k list of values\n",
    "    pk_values = []\n",
    "    # loop over all k. from 1 to k + 1\n",
    "    for i in range(1, k + 1):\n",
    "        # calculate p@i and append list\n",
    "        pk_values.append(pk(y_true, y_pred, i))\n",
    "    # if we have no values in list return 0\n",
    "    if len(pk_values) == 0:\n",
    "        return 0\n",
    "    # else return sum of list over length of list\n",
    "    return sum(pk_values) / len(pk_values)\n",
    "\n",
    "# we can then use the two functions to calculate the AP@k for two lists\n",
    "\n",
    "y_true = [\n",
    "    [1, 2, 3],\n",
    "    [0, 2],\n",
    "    [1],\n",
    "    [2, 3],\n",
    "    [1, 0],\n",
    "    []\n",
    "]\n",
    "\n",
    "y_pred = [\n",
    "    [0, 1, 2],\n",
    "    [1], \n",
    "    [0, 2, 3],\n",
    "    [2, 3, 4, 0],\n",
    "    [0, 1, 2],\n",
    "    [0]\n",
    "]\n",
    "\n",
    "for i in range(len(y_true)):\n",
    "    for j in range(1, 4):\n",
    "        print(\n",
    "        f\"\"\"\n",
    "        y_true={y_true[i]}\n",
    "        y_pred={y_pred[i]}\n",
    "        AP@{j}={apk(y_true[i], y_pred[i], k=j)}\n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "# this is how we get AP@k which is per sample\n",
    "# however we are generally interested in all samples and therefore use MAP@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "868e583a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@1: 0.3333333333333333\n",
      "MAP@2: 0.375\n",
      "MAP@3: 0.3611111111111111\n",
      "MAP@4: 0.34722222222222215\n"
     ]
    }
   ],
   "source": [
    "# as AP@k is per sample and we want to consider all samples we use:\n",
    "# mean average precision at k or MAP@k\n",
    "# this is just the average of AP@k and can be calculated using the following code:\n",
    "\n",
    "def mapk(y_true, y_pred, k):\n",
    "    \"\"\"\n",
    "    Function to calculate  mean average precision at k\n",
    "    :param y_true: list of values, actual classes\n",
    "    :param y_pred: list of values, predicted classes\n",
    "    :return: mean average precision at a given k\n",
    "    \"\"\"\n",
    "    # initalize empty list for apk values\n",
    "    apk_values = []\n",
    "    # loop over all samples\n",
    "    for i in range(len(y_true)):\n",
    "        # store apk values for every sample\n",
    "        apk_values.append(\n",
    "            apk(y_true[i], y_pred[i], k=k)\n",
    "        )\n",
    "    # return mean of apk values in list\n",
    "    return sum(apk_values) / len(apk_values)\n",
    "\n",
    "# we can use the lists before can look at the MAP@k values\n",
    "y_true = [\n",
    "    [1, 2, 3],\n",
    "    [0, 2],\n",
    "    [1],\n",
    "    [2, 3],\n",
    "    [1, 0],\n",
    "    []\n",
    "]\n",
    "\n",
    "y_pred = [\n",
    "    [0, 1, 2],\n",
    "    [1], \n",
    "    [0, 2, 3],\n",
    "    [2, 3, 4, 0],\n",
    "    [0, 1, 2],\n",
    "    [0]\n",
    "]\n",
    "\n",
    "print('MAP@1: ' + str(mapk(y_true, y_pred, k=1)))\n",
    "print('MAP@2: ' + str(mapk(y_true, y_pred, k=2)))\n",
    "print('MAP@3: ' + str(mapk(y_true, y_pred, k=3)))\n",
    "print('MAP@4: ' + str(mapk(y_true, y_pred, k=4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
